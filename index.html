<!DOCTYPE html>
<html lang="nl">
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta content="text/html; charset=UTF-8" http-equiv="content-type">
    <title>HR AI-Hub - Hogeschool Rotterdam</title>
    <link rel="stylesheet" href="https://www.w3.org/StyleSheets/TR/2016/base.css">
    <style>
        body {
            display: flex;
            flex-direction: column;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: #fff;
        }

        .head {
            width: 100%;
            border-bottom: 3px solid #005a9c;
            margin-bottom: 2em;
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding-bottom: 1em;
        }

        .logo-container {
            display: flex;
            align-items: center;
            gap: 20px;
        }

        .status-badge {
            background: #28a745;
            color: white;
            padding: 8px 15px;
            border-radius: 5px;
            font-weight: bold;
            text-transform: uppercase;
            font-size: 0.9em;
        }

        .main-container {
            display: flex;
            gap: 40px;
        }

        /* Sidebar TOC */
        nav#toc {
            flex: 0 0 280px;
            position: sticky;
            top: 20px;
            height: fit-content;
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            border: 1px solid #e9ecef;
        }

        nav#toc h2 {
            font-size: 1.2em;
            margin-top: 0;
            color: #005a9c;
            border: none;
        }

        nav#toc ol {
            padding-left: 1.5em;
        }

        nav#toc li {
            margin-bottom: 12px;
        }

        nav#toc a {
            text-decoration: none;
            color: #005a9c;
        }

        nav#toc a:hover {
            text-decoration: underline;
        }

        /* Content Area */
        main {
            flex: 1;
        }

        h2 {
            color: #005a9c;
            border-bottom: 1px solid #eee;
            padding-bottom: 0.3em;
        }

        .project-card {
            border: 1px solid #ddd;
            padding: 20px;
            margin: 20px 0;
            border-radius: 8px;
            background: #fdfdfd;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        }

        .project-card h3 {
            margin-top: 0;
            color: #d32f2f;
        }

        .tag {
            display: inline-block;
            background: #eef2ff;
            color: #3730a3;
            padding: 2px 10px;
            border-radius: 12px;
            font-size: 0.8em;
            margin-right: 5px;
            font-weight: bold;
            border: 1px solid #c7d2fe;
        }

        code {
            color: #c83500;
            background: #f4f4f4;
            padding: 2px 4px;
            border-radius: 3px;
        }

        table.simple-table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5em 0;
        }

        table.simple-table th, table.simple-table td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }

        table.simple-table th {
            background-color: #005a9c;
            color: white;
        }

        .link-btn {
            display: inline-block;
            margin-top: 15px;
            padding: 10px 20px;
            background: #005a9c;
            color: white !important;
            text-decoration: none;
            border-radius: 5px;
        }

        @media (max-width: 900px) {
            .main-container { flex-direction: column; }
            nav#toc { position: relative; width: auto; flex: none; }
        }
    </style>
	</head>
	<body class="h-entry">
		<header class="head">
			<div class="logo-container">
				<img src="respec/style/logos/HR-Logo.png" alt="HR AI Hub" width="75">
				<div>
					<h1>HR AI-Hub Pilot 2026</h1>
		<p>
		  <strong>Opdrachtgever:<br> </strong> &nbsp;Programma AI &amp; Ethiek Hogeschool Rotterdam (HR) <br> <br> 
	    <strong>Gerealiseerd door:<br> </strong> Alfons Looman &amp; Rob van der Willigen <br>
	     in samenwerking met  <a href="https://www.hogeschoolrotterdam.nl/samenwerking/andere-samenwerkingsvormen/datalabs/" target="_blank">
			<strong> Datalabs: </strong> EAS / Healthcare / AI  SusTech </p>

    </header>
    <div class="main-container">
	  <nav id="toc">
			  <h2 class="introductory" id="inhoudsopgave">Inhoudsopgave</h2>
			  <ol class="toc">
				<li class="tocline">
				  <a class="tocxref" href="#context"><span class="secno">1. </span>Context & Doel</a>
				  <ol class="toc">
					<!-- <li class="tocline"><a class="tocxref" href="#doel-positie"><span class="secno">1.1 </span>Doel en positie binnen de organisatie</a></li>
					<li class="tocline"><a class="tocxref" href="#triage"><span class="secno">1.2 </span>Eerste aanspreekpunt (triage) en doorverwijzing</a></li> -->
				  </ol>
				</li>

				<li class="tocline">
				  <a class="tocxref" href="#showcase"><span class="secno">2. </span>Gerealiseerde Projecten</a>
				</li>

				<li class="tocline">
				  <a class="tocxref" href="#modellen"><span class="secno">3. </span>Beschikbare Modellen</a>
				</li>

				<li class="tocline">
				  <a class="tocxref" href="#onboarding"><span class="secno">4. </span>Onboarding & Support</a>
				  <ol class="toc">
					<!--<li class="tocline"><a class="tocxref" href="#aanvragen-ondersteuning"><span class="secno">4.1 </span>Aanvragen van ondersteuning</a></li>
					<li class="tocline"><a class="tocxref" href="#support-proces"><span class="secno">4.2 </span>Support-proces en contact</a></li> -->
				  </ol>
				</li>
				  
				<li class="tocline">
				  <a class="tocxref" href="#overeenkomst"><span class="secno">2. </span>Pilot Overeenkomst</a> <br> <br>
				</li>  
				  
			  </ol>
	   </nav>

        <main>
            <section id="context">
                <h1>1. Context &amp; Doel</h1>
						<p>  
					    Met de ontwikkeling van de AI-hub trekken
						<a href="https://www.surf.nl/themas/artificial-intelligence/projecten-en-samenwerkingen/ai-hub" target="_blank"><strong> SURF en Npuls </strong></a>
						tezamen op om een toekomstbestendig Nederlands AI-platform te creëren dat op een verantwoorde en veilige manier toegang geeft tot grote, rekenintensieve taalmodellen. Hierbij vormen de publieke waarden: “autonomie, menselijkheid en rechtvaardigheid” een centraal uitgangspunt. </p>  
						<p>  
					    Dankzij de <strong>HR SURF AI-Hub Pilot</strong> krijgen onderzoekers, docenten, ondersteuners en studenten van <strong>Hogeschool Rotterdam (HR)</strong> de mogelijkheid om op een veilige en gecontroleerde manier te werken met generatieve AI-taalmodellen. De AI-Hub draait volledig in SURF’s eigen datacenters en zal na certificering ook gebruikt kunnen worden voor vertrouwelijke data. Op deze wijze ontsluit de AI-Hub de benodigde infrastructuur waarmee verschillende AI-workflows duurzaam kunnen worden ingericht. </p>  
						<p>  
					    Toegang tot specifieke taalmodellen verloopt via een API-koppeling die compatibel is met de OpenAI-standaard. De onderliggende source-code is volledig door SURF ontwikkeld en wordt als open source beschikbaar gesteld, zodat developers deze data-fabric (software + hardware) kunnen gebruiken en verder ontwikkelen binnen hun eigen omgeving zonder eerst te moeten investeren in kostbare AI-infrastructuur. </p>  	
				
						<p>  
					    Het doel is om de AI-Hub te benutten als duurzame experimenteer‑ en ontwikkelomgeving voor betrouwbare en reproduceerbare Gen-AI applicaties gericht op <strong>waarheidsvinding (“truth finding”)</strong> binnen onderwijs en onderzoek aan Hogeschool Rotterdam.</p>
				
				<div class="example"><h1>Truth Finding [“Waarheidsvinding”]</h1> 
				  <ul>  
				    <li>  
					  <strong>Detectie en mitigatie van hallucinaties.</strong><br>  
					  Dit betreft het identificeren en reduceren van onjuiste, verzonnen of niet‑onderbouwde informatie in de gegenereerde output van LLM’s.   
							Bijvoorbeeld: het toepassen van algoritmen die tekstuele inconsistenties signaleren, of het integreren van verificatiemodules die feitelijke beweringen automatisch toetsen aan betrouwbare databases   
							(zoals wetenschappelijke literatuur of officiële statistieken).  <br>
							  
					  <ul style="list-style-type: disc; padding-left: 1.2em; margin: 0;">
						<li style="color: #8B0000; font-size: 0.85em; line-height: 1.1;">
						  Anh-Hoang, D., Tran, V., & Nguyen, L.-M. (2025). 
						  <a href="https://doi.org/10.3389/frai.2025.1622292" 
							   style="color: #8B0000; text-decoration: none;" 
							   target="_blank">Survey and analysis of hallucinations in large language models: Attribution to prompting strategies or model behavior</a>. 
						  <i>Frontiers in Artificial Intelligence, 8</i>, 1622292. 
						  <a href="https://doi.org/10.3389/frai.2025.1622292" 
							   style="color: #8B0000; text-decoration: underline;" 
							   target="_blank">https://doi.org/10.3389/frai.2025.1622292</a>
					    </li>
					  </ul><br>

				    <li>  
					  <strong>Geautomatiseerde fact‑checking en claimverificatie.</strong><br>  
					  LLM’s kunnen worden ingezet als ondersteunende instrumenten voor de verificatie van feitelijke uitspraken.   
							Denk aan toepassingen waarbij een model nieuwsberichten, beleidsdocumenten of sociale‑media‑posts vergelijkt met erkende bronnen   
							(bijv. encyclopedische datasets, juridische archieven, of peer‑reviewed publicaties) om de waarheidswaarde van claims te beoordelen.  
				    </li>
							
														  
					  <ul style="list-style-type: disc; padding-left: 1.2em; margin: 0;">
						<li style="color: #8B0000; font-size: 0.85em; line-height: 1.1;">
						  Rahman, S. S., Islam, M. A., Alam, M. M., Zeba, M., Rahman, M. A., Chowa, S. S., … & Azam, S. (2026). 
						  <a href="https://doi.org/10.1007/s10462-026-11111-5" 
							   style="color: #8B0000; text-decoration: none;" 
							   target="_blank">Hallucination to truth: A review of fact-checking and factuality evaluation in large language models</a>. 
						  <i>Artificial Intelligence Review</i>. 
						  <a href="https://doi.org/10.1007/s10462-026-11111-5" 
							   style="color: #8B0000; text-decoration: underline;" 
							   target="_blank">https://doi.org/10.1007/s10462-026-11111-5</a>
					    </li>
					  </ul>
					  <ul style="list-style-type: disc; padding-left: 1.2em; margin: 0;">
						<li style="color: #8B0000; font-size: 0.85em; line-height: 1.1;">
						  Krishnamurthy, V., & Balaji, V. (2024). 
						  <a href="https://doi.org/10.1109/ACCESS.2024.3520187" 
							   style="color: #8B0000; text-decoration: none;" 
							   target="_blank">Yours truly: A credibility framework for effortless LLM-powered fact checking</a>. 
						  <i>IEEE Access, 12</i>, 195152-195173. 
						  <a href="https://doi.org/10.1109/ACCESS.2024.3520187" 
							   style="color: #8B0000; text-decoration: underline;" 
							   target="_blank">https://doi.org/10.1109/ACCESS.2024.3520187</a>
					    </li>
					  </ul><br>


				    <li>  
					  <strong>Bron‑gegronde (“grounded”) attributie.</strong><br>  
				    Geautomatiseerde koppeling van standpunten aan geverifieerde broninformatie ("Contextually grounded research"). Een LLM moet niet alleen antwoorden genereren, maar ook transparant maken waarop deze zijn gebaseerd — door expliciete verwijzingen naar rapporten, datasets of publicaties.
					Zo wordt reproduceerbaarheid en betrouwbaarheid versterkt: elke bewering kan dan worden herleid tot concrete passages in de onderliggende literatuuren/of sleutel publicaties.
					Benaderingen zoals “Attribute First, then Generate” laten bovendien zien dat het eerst selecteren van relevante bronsegmenten en pas daarna genereren resulteert in fijnmazige, zin‑voor‑zin‑attributie. Hierdoor worden de tijdsdruk en cognitieve belasting bij menselijke fact‑checking aanzienlijk verminderd.</li>  
					    
					<ul style="list-style-type: disc; padding-left: 1.2em; margin: 0;">
					<li style="color: #8B0000; font-size: 0.85em; line-height: 1.1;">
					Asai, A., He, J., Shao, R., et al. (2026). 
					<a href="https://doi.org/10.1038/s41586-025-10072-4" 
					   style="color: #8B0000; text-decoration: none;" 
					   target="_blank">Synthesizing scientific literature with retrieval-augmented language models</a>. 
					<i>Nature</i>. 
					<a href="https://doi.org/10.1038/s41586-025-10072-4" 
					   style="color: #8B0000; text-decoration: underline;" 
					   target="_blank">https://doi.org/10.1038/s41586-025-10072-4</a>
					</li>
					</ul>

					<ul style="list-style-type: disc; padding-left: 1.2em; margin: 0.5em 0;">
					<li style="color: #8B0000; font-size: 0.85em; line-height: 1.1;">
					Slobodkin, A., Hirsch, E., Cattan, A., Schuster, T., & Dagan, I. (2024, August). 
					<a href="https://doi.org/10.18653/v1/2024.acl-long.182" style="color: #8B0000; text-decoration: none;" target="_blank">
					Attribute first, then generate: Locally-attributable grounded text generation
					</a>. 
					<i>In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</i>, 3309–3344. 
					<a href="https://doi.org/10.18653/v1/2024.acl-long.182" style="color: #8B0000; text-decoration: underline;" target="_blank">
					https://doi.org/10.18653/v1/2024.acl-long.182
					</a>
					</li>
					</ul><br>
					  
					<li>  
					  <strong>Onzekerheid, kalibratie en “weten dat je het niet weet”</strong><br>  
				    LLMs dwingen om kennisgrenzen transperant te maken —welke informatie is zee waarschijnlijk en waarom, —waar begint de onzekerheid, en wat ligt buiten het bereik van de LLM?
					Gekalibreerde systemen berekenen waarschijnlijkheid op een correcte claim en genereren anrtropomorfische uitspraken zoals: "ik weet het niet" boven zelfverzekerde onwaarheden. Frameworks zoals "Abstention / refusal als truth‑finding‑strategie" (UALIGN) trainen modellen om feiten nauwkeriger te formuleren en onbekende vragen bewust te weigeren, wat de truthfulness-score verhoogt. Benchmarks als TruthfulQA evalueren deze dimensie apart: niet alleen wat het model zegt, maar hoe zeker en wanneer het moet zwijgen.</li>  
					  
					<ul style="list-style-type: disc; padding-left: 1.2em; margin: 0.5em 0;">
					<li style="color: #8B0000; font-size: 0.85em; line-height: 1.1;">
					Xue, B., Mi, F., Zhu, Q., Wang, H., Wang, R., Wang, S., … & Wong, K. F. (2025). 
					<a href="https://doi.org/10.18653/v1/2025.acl-long.299" style="color: #8B0000; text-decoration: none;" target="_blank">
					UAalign: Leveraging uncertainty estimations for factuality alignment on large language models
					</a>. 
					<i>In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</i>, 6002–6024. 
					<a href="https://doi.org/10.18653/v1/2025.acl-long.299" style="color: #8B0000; text-decoration: underline;" target="_blank">
					https://doi.org/10.18653/v1/2025.acl-long.299
					</a>
					</li>
					</ul>

					<ul style="list-style-type: disc; padding-left: 1.2em; margin: 0.5em 0;">
						<li style="color: #8B0000; font-size: 0.85em; line-height: 1.1;">
						Qian, C., Acikgoz, E. C., Wang, H., Chen, X., Sil, A., Hakkani-Tür, D., Tur, G., & Ji, H. (2025, July). 
						<a href="https://doi.org/10.18653/v1/2025.findings-acl.239" style="color: #8B0000; text-decoration: none;" target="_blank">
						SMART: Self-aware agent for tool overuse mitigation
						</a>. 
						<i>Findings of the Association for Computational Linguistics: ACL 2025</i>, 4604–4621. 
						<a href="https://doi.org/10.18653/v1/2025.findings-acl.239" style="color: #8B0000; text-decoration: underline;" target="_blank">
						https://doi.org/10.18653/v1/2025.findings-acl.239
						</a>
						</li>
					</ul>

				  
				  </ul><br>
				</div>
            </section>
				
						
		  <p>
						Deze ambitie sluit aan bij de voorgenomen inrichting van hogeschool Rotterdam in vijf domeinen, waarin onderwijs en onderzoek rond één arbeidsmarktsector worden samengebracht en elkaar versterken.</p>  
				
						<table class="simple-table">
						<thead>
							<tr>
								<th>Domein</th>
								<th>Instituten / kenniscentra</th>
								<th>Korte toelichting</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td><strong>Mens &amp; Maatschappij</strong></td>
								<td>IvL, ISO, kenniscentrum Talentontwikkeling</td>
								<td>Onderwijs en onderzoek rond mens, maatschappij en sociale vraagstukken.</td>
							</tr>
							<tr>
								<td><strong>Design Academy</strong></td>
								<td>WdKA, CMI, kenniscentrum WdKA, Creating010</td>
								<td>Ontwerp, creatieve industrie en digitale media in onderwijs en praktijkgericht onderzoek.</td>
							</tr>
							<tr>
								<td><strong>Stad, Haven en Industrie</strong></td>
								<td>IGO, EAS, RMI, CoE HR Tech</td>
								<td>Techniek, haven, logistiek en industrie in samenhang met de Rotterdamse regio.</td>
							</tr>
							<tr>
								<td><strong>Zorg</strong></td>
								<td>IvG, kenniscentrum Zorginnovatie (KCZ)</td>
								<td>Gezondheidszorg en zorginnovatie, met focus op praktijkgericht onderzoek en professionalisering.</td>
							</tr>
							<tr>
								<td><strong>Business</strong></td>
								<td>RBS, kenniscentrum Business Innovation</td>
								<td>Business, ondernemerschap en innovatie in samenwerking met het regionale werkveld.</td>
							</tr>
						</tbody>
						</table>
				


            <section id="showcase">
                <h1>2. Gerealiseerde Implementaties (Showcases)</h1>
				
						<p>  
					    Showcases laten concreet zien hoe de HR AI‑Hub‑pilot veilige infrastructuur, onderwijsinnovatie en geavanceerde Truth-Finding AI‑workflows met elkaar verbindt. </p> 
                
                <div class="project-card">
                    <h3>HR-DataLab Healthcare: Research Support Stack</h3>
                    <p>Een robuuste omgeving voor zorgonderzoek met integratie van SRAM voor veilige toegang en Langflow voor visuele AI-workflows.</p>
                    <span class="tag">SRAM</span><span class="tag">Docker</span><span class="tag">Langflow</span>
                    <br>
                    <a href="https://github.com/HR-DataLab-Healthcare/RESEARCH_SUPPORT/tree/main/PROJECTS/SRAM_DOCKER_LANGFLOW" class="link-btn">Bekijk op GitHub</a>
                </div>

                <div class="project-card">
                    <h3>CMGT: Chat with Einstein</h3>
                    <p>Een 'Socratic Agent' ontwikkeld voor de opleiding Creative Media and Game Technologies om studenten te ondersteunen bij leerprocessen.</p>
                    <span class="tag">Onderwijs</span><span class="tag">Socratic Agent</span><span class="tag">Live Demo</span>
                    <br>
                    <a href="https://cmgt.socratic-agent.src.surf-hosted.nl/" class="link-btn">Bezoek Applicatie</a>
                </div>
            </section>

            <section id="modellen">
                <h1>3. Beschikbare Modellen</h1>
                <p>De volgende modellen draaien momenteel in de AI-Hub Pilot omgeving:</p>
                <table class="simple-table">
                    <thead>
                        <tr>
                            <th>Modaliteit</th>
                            <th>Model / Alias</th>
                            <th>Toepassing</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Tekst (Large)</strong></td>
                            <td><code>Llama 3.3 70b Instruct AWQ</code></td>
                            <td>Complexe tekstverwerking</td>
                        </tr>
                        <tr>
                            <td><strong>Tekst (Medium)</strong></td>
                            <td><code>Mistral-Small-3.2-24B-Instruct</code></td>
                            <td>Efficiënt EU-alternatief</td>
                        </tr>
                        <tr>
                            <td><strong>Code</strong></td>
                            <td><code>Qwen 2.5 Coder 32B Instruct AWQ</code></td>
                            <td>Hulp bij programmeren</td>
                        </tr>
                        <tr>
                            <td><strong>Beeld (Analyse)</strong></td>
                            <td><code>Qwen 2.5 VL 32B Instruct AWQ</code></td>
                            <td>Visuele analyse / Vision</td>
                        </tr>
                        <tr>
                            <td><strong>Spraak</strong></td>
                            <td><code>Whisper speech-to-text Dutch</code></td>
                            <td>Nederlandse transcripties</td>
                        </tr>
                        <tr>
                            <td><strong>Embeddings</strong></td>
                            <td><code>Qwen/Qwen3-Embedding-8B</code></td>
                            <td>RAG & Semantisch zoeken</td>
                        </tr>
                        <tr>
                            <td><strong>Experimenteel</strong></td>
                            <td><code>openai/gpt-oss-120b</code></td>
                            <td>Open-weight onderzoek</td>
                        </tr>
                    </tbody>
                </table>
            </section>

		<section id="onboarding">
			<h1>4. Onboarding &amp; Support</h1>
			<p>Voor docenten en onderzoekers die gebruik willen maken van de AI-Hub infrastrutuur, zijn de volgende bronnen en kanalen beschikbaar:</p>

			<ul>
				<li>
					<strong>Documentatie:</strong> 
					Technische specificaties van de endpoints en informatie over latency-modi zijn beschikbaar via de SURF Servicedesk (inloggen via SURF/SRAM vereist).
					[<a href="https://servicedesk.surf.nl/wiki/spaces/WIKI/pages/219086851/AI-Hub+WiLLMa+Pilot+phase#AIHub(WiLLMa)%3APilotphase-Latencymode" target="_blank">Servicedesk SURF</a>]
				</li>
				<li>
					<strong>Python SDK &amp; Voorbeelden:</strong> 
					Praktische code-voorbeelden voor tool-calling, visuele workflows en diverse model-modaliteiten zijn te vinden in de Research Support repositories van de deelnemende datalabs.
					[<a href="https://github.com/HR-DataLab-Healthcare/RESEARCH_SUPPORT/tree/main/PROJECTS/SRAM_DOCKER_LANGFLOW" target="_blank">Zie o.a. de Langflow implementie van Willma LLMs door datalab Healthcare</a>]
				</li>
				<li>
					<strong>Project Intake &amp; Support:</strong> 
					Nieuwe AI-Hub projecten worden gefaciliteerd via een gestructureerd intakeproces. 
					[<a href="https://github.com/HR-DataLab-Healthcare/RESEARCH_SUPPORT/blob/main/PROJECTS/Intake_Procedure_Data_Science_Projects/Readme.md" target="_blank">Intakeproces Data Science</a>] 
				</li>
				<li>
					<strong>Lopende initiatieven: </strong> 
					Informatie over lopende initiatieven is te verkrijgen via <a href="https://www.hogeschoolrotterdam.nl/samenwerking/andere-samenwerkingsvormen/datalabs/" target="_blank"><strong> Datalabs: </strong> EAS / Healthcare / AI  SusTech </p> <a></a></a>
				</li>
			</ul>
		</section>
				
			<section id="overeenkomst"><h1>5. Pilotovereenkomst AI-Hub</h1>
                <p>De deelname van Hogeschool Rotterdam aan de AI-Hub is formeel bekrachtigd op 6 december 2026 middels de <strong>Pilotovereenkomst AI-hub</strong>. <br>
					Deze overeenkomst definieert de kaders voor het gebruik van de infrastructuur gedurende de testfase.</p>
			  <div class="example"><h2>Kernpunten uit de overeenkomst</h2> 
				  <ul>  
                        <li><strong>Doel: <br> </strong> Het testen en valideren van de AI-Hub infrastructuur in een academische context.</li>
                        <li><strong>Verantwoordelijkheid:</strong> <br> SURF faciliteert de hardware en basissoftware; <br>Hogeschool Rotterdam (HR)is verantwoordelijk voor de ingevoerde data en specifieke applicaties.</li>
					    <li><strong>Certificaten waarover de Verwerker (SURF)  beschikt: <br> </strong> Alle diensten van SURF vallen in principe onder de ISO 27001-certificering.
					  	<br>
							<a href="surf-verklaring-van-toepasselijkheid-2024.pdf" style="color: red; text-decoration: underline;" target="_blank">
								surf-verklaring-van-toepasselijkheid-2024.pdf
							</a>
                        <li><strong>Vertrouwelijkheid: <br> </strong> Er gelden strikte afspraken over informatiebeveiliging en het gebruik van open-source componenten.</li>
                        <li><strong>Looptijd: <br>  </strong> De overeenkomst is specifiek van kracht voor de duur van de pilotfase (2025-2026).</li>
					  <Li><strong>Archivering: <br> </strong>De getekende versie van dit document is gearchiveerd door de afdeling Juridische Zaken van de Hogeschool Rotterdam <br> 
						  en ingezien door privacy officer Sam Wubben. <strong>Contact:</strong> <a href="mailto:privacy@hr.nl">privacy@hr.nl</a>
                    </ul><br>
              </div>
            </section>
			
        </main>
    </div>

    <footer style="margin-top: 50px; border-top: 1px solid #ccc; padding: 20px 0; font-size: 0.8em; color: #666;">
        <p>© 2026 Hogeschool Rotterdam | In samenwerking met SURF AI-Hub Pilot Programma.</p>
    </footer>
</body>
</html>